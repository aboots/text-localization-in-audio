{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook, each audio file are downloaded and they will be segmented on silnces. To ensure meaningful segmentation, training data chunks should be longer than 10 seconds."
      ],
      "metadata": {
        "id": "QaPJ-yJGEkYy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pydub import AudioSegment\n",
        "from pydub.silence import split_on_silence,detect_silence,detect_nonsilent\n",
        "import pandas as pd\n",
        "import json\n",
        "import os"
      ],
      "metadata": {
        "id": "A1M4GEYGnyvN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -i radiomarz_urls.txt -P audios"
      ],
      "metadata": {
        "id": "79uKMWv-GbBU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = {}\n",
        "\n",
        "for filename in os.listdir('audios/'):\n",
        "  audio_file = AudioSegment.from_file('audios/'+filename)\n",
        "\n",
        "  #split on silent sections\n",
        "  nonsilent_ranges = detect_nonsilent(audio_file, min_silence_len=900, silence_thresh=-25, seek_step=50)\n",
        "\n",
        "  length = 0\n",
        "  new_segments = []\n",
        "  new_start = 0\n",
        "\n",
        "  for start, end in nonsilent_ranges:\n",
        "\n",
        "    #Skip the last 3 min of each episode (The ending music of each episode)\n",
        "    if len(audio_file) - end < 3*60*1000: \n",
        "      new_segments.append([new_start, end])\n",
        "      break\n",
        "\n",
        "    # to have chuncks larger than 10 seconds\n",
        "    if length > 10000:\n",
        "      new_segments.append([new_start, new_end])\n",
        "      new_start = start\n",
        "      new_end   = end\n",
        "    \n",
        "    new_end   = end\n",
        "    length = new_end - new_start\n",
        "  \n",
        "  time_segments = [{\"start_time\": start/1000, \"end_time\": end/1000} for start, end in new_segments]\n",
        "  results[filename] = time_segments "
      ],
      "metadata": {
        "id": "u52ABeXcMQXi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"persian_dataset_chunks.json\", \"w\") as inFile:\n",
        "  json.dump(results,inFile,indent=1)"
      ],
      "metadata": {
        "id": "NA3xf7bzWsnU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'{len(episodes_length)} episodes : {sum(episodes_length)//60} hours')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SENS3szCkxIX",
        "outputId": "2da2a2b0-1e01-4ed9-84d7-ad8442d1dc4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "42 episodes : 77.0 hours\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "interpreter": {
      "hash": "a1a46404003b1888471f66733c8ff43ecbbd22069e04669a0d47e7a2f84d0bb4"
    },
    "kernelspec": {
      "display_name": "Python 3.7.4 64-bit ('qenv': venv)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}