{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8dd77174",
   "metadata": {},
   "source": [
    "****keyphrase extraction for persian****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21999a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the packages\n",
    "\n",
    "from hazm import Normalizer, word_tokenize, sent_tokenize\n",
    "from hazm import stopwords_list\n",
    "from hazm import Stemmer\n",
    "from hazm import word_tokenize\n",
    "from yake import KeywordExtractor\n",
    "import codecs\n",
    "import collections\n",
    "from multi_rake import Rake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004b973f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function in order to preprocess the input text\n",
    "def preprocess(text):\n",
    "        # Normalize the text\n",
    "    normalizer = Normalizer()\n",
    "    normalized_text = normalizer.normalize(text)\n",
    "\n",
    "    # Tokenize the text into words\n",
    "    words = word_tokenize(normalized_text)\n",
    "\n",
    "    # Remove stop words\n",
    "    stopwords = stopwords_list()\n",
    "    filtered_words = [word for word in words if word not in stopwords]\n",
    "\n",
    "    #print(stemmed_words)\n",
    "    result_text = \" \".join(filtered_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1bcb571",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text to extract keywords from\n",
    "\n",
    " # The first method is yake.\n",
    "\n",
    "def yake(text):\n",
    "    \n",
    "    preprocess(text)\n",
    "\n",
    "    # Create a YAKE keyword extractor\n",
    "    kw_extractor = KeywordExtractor()\n",
    "\n",
    "    # Extract keywords from the text\n",
    "    keywords = kw_extractor.extract_keywords(result_text)\n",
    "    \n",
    "    return keywords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d56ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The second method is rake\n",
    "\n",
    "def rake(text):\n",
    "    \n",
    "    preprocess(text)\n",
    "# \n",
    "    rake = Rake(\n",
    "        min_chars=3,\n",
    "        max_words=3,\n",
    "        min_freq=1,\n",
    "        language_code=None,  \n",
    "        stopwords=None, \n",
    "        lang_detect_threshold=50,\n",
    "        max_words_unknown_lang=2,\n",
    "        generated_stopwords_percentile=80,\n",
    "        generated_stopwords_max_len=3,\n",
    "        generated_stopwords_min_freq=2,\n",
    "    )\n",
    "    keywords = rake.apply(result_text)\n",
    "    return keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf028db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the keywords for an example text.\n",
    "\n",
    "text = \"پردازش زبان‌های طبیعی یکی از زیرشاخه‌های بااهمیت در حوزه‌ی گسترده‌ی علوم رایانه، هوش مصنوعی، که به تعامل بین کامپیوتر و زبان‌های (طبیعی) انسانی می‌پردازد؛ بنابراین پردازش زبان‌های طبیعی بر ارتباط انسان و رایانه، متمرکز است. پس چالش اصلی و عمده در این زمینه درک زبان طبیعی و ماشینی کردن فرایند درک و برداشت مفاهیم بیان‌شده با یک زبان طبیعیِ انسانی است. به تعریف دقیق‌تر، پردازش زبان‌های طبیعی عبارت است از استفاده از رایانه برای پردازش زبان گفتاری و زبان نوشتاری. بدین معنی که رایانه‌ها را قادر سازیم که گفتار یا نوشتار تولید شده در قالب و ساختار یک زبان طبیعی را تحلیل و درک نموده یا آن را تولید نمایند. در این صورت، با استفاده از آن می‌توان به ترجمهٔ زبان‌ها پرداخت، از صفحات وب و بانک‌های اطلاعاتیِ نوشتاری جهت پاسخ‌دادن به پرسش‌ها استفاده کرد، یا با دستگاه‌ها، مثلاً برای مشورت‌گرفتن به گفت‌وگو پرداخت. این‌ها تنها مثال‌هایی از کاربردهای متنوع پردازش زبان‌های طبیعی هستند. هدف اصلی در پردازش زبان طبیعی، ایجاد تئوری‌هایی محاسباتی از زبان، با استفاده از الگوریتم‌ها و ساختارهای داده‌ای موجود در علوم رایانه است. بدیهی است که در راستای تحقق این هدف، نیاز به دانشی وسیع از زبان است و علاوه بر محققان علوم رایانه، نیاز به دانش زبان‌شناسان نیز در این حوزه می‌باشد. با پردازش اطلاعات زبانی می‌توان آمار مورد نیاز برای کار با زبان طبیعی را استخراج کرد. کاربردهای پردازش زبان طبیعی به دو دسته کلی قابل تقسیم است: کاربردهای نوشتاری و کاربردهای گفتاری. از کاربردهای نوشتاری آن می‌توان به استخراج اطلاعاتی خاص از یک متن، ترجمه یک متن به زبانی دیگر یا یافتن مستنداتی خاص در یک پایگاه داده نوشتاری (مثلاً یافتن کتاب‌های مرتبط به هم در یک کتابخانه) اشاره کرد. نمونه‌هایی از کاربردهای گفتاری پردازش زبان عبارتند از: سیستم‌های پرسش و پاسخ انسان با رایانه، سرویس‌های اتوماتیک ارتباط با مشتری از طریق تلفن، سیستم‌های آموزش به فراگیران یا سیستم‌های کنترلی توسط صدا. در سالهای اخیر این حوزه تحقیقاتی توجه دانشمندان را به خود جلب کرده‌است و تحقیقات قابل ملاحظه‌ای در این زمینه صورت گرفته‌است.\"\n",
    "\n",
    "for kw in yake(text):\n",
    "    print(kw[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
