{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Requirements","metadata":{}},{"cell_type":"code","source":"!pip install transformers\n!pip install datasets\n!pip install pytorch_metric_learning\n!pip install opendatasets\n!pip install pydub\n!pip install gdown\n!pip install tabulate","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install git+https://github.com/huggingface/transformers","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom transformers import AutoProcessor, Wav2Vec2Model\nfrom datasets import load_dataset\nfrom transformers import AutoTokenizer, AutoModel\nimport numpy as np\nimport torch.nn.functional as F\nimport torch.nn as nn\nfrom tqdm import tqdm\nfrom torch.utils.data import Dataset, DataLoader, random_split\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\nfrom time import time\nfrom matplotlib import pyplot as plt\nfrom sklearn.metrics import accuracy_score\nimport os\nfrom pydub import AudioSegment\nimport opendatasets as od\nimport pandas as pd\nimport gc\nimport random\nimport pickle as pkl\nimport gdown\nfrom tabulate import tabulate","metadata":{"id":"9RcYEd6H5yyT","execution":{"iopub.status.busy":"2023-03-10T13:24:22.863961Z","iopub.execute_input":"2023-03-10T13:24:22.864402Z","iopub.status.idle":"2023-03-10T13:24:22.900586Z","shell.execute_reply.started":"2023-03-10T13:24:22.864360Z","shell.execute_reply":"2023-03-10T13:24:22.899486Z"},"trusted":true},"execution_count":182,"outputs":[]},{"cell_type":"markdown","source":"## Load Files","metadata":{}},{"cell_type":"code","source":"url = \"https://drive.google.com/file/d/1-390QxYWgKkhxQLttpEPfQMk0xr8Lb2Y/view?usp=share_link\"\noutput = \"test_dataset.pkl\"\ngdown.download(url, output, quiet=False, fuzzy=True)\n\nurl = \"https://drive.google.com/file/d/1MWAWrtDt2iS5OhKlsIIt-k1ROSP5M4iM/view?usp=share_link\"\noutput = \"final_model.pt\"\ngdown.download(url, output, quiet=False, fuzzy=True)\n\nurl = \"https://drive.google.com/file/d/1-02DOpowTyAZULS38dUq3E4e4qYxzXU1/view?usp=share_link\"\noutput = \"multimodal_model.pt\"\ngdown.download(url, output, quiet=False, fuzzy=True)","metadata":{"execution":{"iopub.status.busy":"2023-03-10T12:57:17.548607Z","iopub.execute_input":"2023-03-10T12:57:17.549549Z","iopub.status.idle":"2023-03-10T12:57:34.952100Z","shell.execute_reply.started":"2023-03-10T12:57:17.549496Z","shell.execute_reply":"2023-03-10T12:57:34.951072Z"},"trusted":true},"execution_count":76,"outputs":[{"name":"stderr","text":"Downloading...\nFrom: https://drive.google.com/uc?id=1-390QxYWgKkhxQLttpEPfQMk0xr8Lb2Y\nTo: /kaggle/working/test_dataset.pkl\n100%|██████████| 476M/476M [00:04<00:00, 114MB/s]  \nDownloading...\nFrom: https://drive.google.com/uc?id=1MWAWrtDt2iS5OhKlsIIt-k1ROSP5M4iM\nTo: /kaggle/working/final_model.pt\n100%|██████████| 846M/846M [00:07<00:00, 115MB/s]  \nDownloading...\nFrom: https://drive.google.com/uc?id=1-02DOpowTyAZULS38dUq3E4e4qYxzXU1\nTo: /kaggle/working/multimodal_model.pt\n100%|██████████| 10.7M/10.7M [00:00<00:00, 117MB/s]\n","output_type":"stream"},{"execution_count":76,"output_type":"execute_result","data":{"text/plain":"'multimodal_model.pt'"},"metadata":{}}]},{"cell_type":"markdown","source":"## Preparing Data","metadata":{}},{"cell_type":"code","source":"class TestDataset(Dataset):\n    def __init__(self, data):\n        self.data = data\n        self.id_to_idx = {}\n        for i in range(len(self.data)):\n            d_id = self.data[i]['id']\n            self.id_to_idx[d_id] = i\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, index):\n        sample = self.data[index]\n        text = sample['keywords']\n        candidate_idxs = sample['candidates']\n        label = sample['label']\n\n        # Get the audio embeddings of the candidate instances\n        candidates_audio_embeddings = []\n        for d_id in candidate_idxs:\n            candidate = self.data[self.id_to_idx[d_id]]\n            candidate_audio_embedding = torch.tensor(candidate['audio_embedding'])\n            candidates_audio_embeddings.append(candidate_audio_embedding)\n        candidates_audio_embeddings = torch.stack(candidates_audio_embeddings)\n\n        return text, candidates_audio_embeddings, label","metadata":{"id":"1yJW4hi0vfCA","execution":{"iopub.status.busy":"2023-03-10T13:10:46.915899Z","iopub.execute_input":"2023-03-10T13:10:46.916296Z","iopub.status.idle":"2023-03-10T13:10:46.925231Z","shell.execute_reply.started":"2023-03-10T13:10:46.916261Z","shell.execute_reply":"2023-03-10T13:10:46.924025Z"},"trusted":true},"execution_count":145,"outputs":[]},{"cell_type":"code","source":"with open('test_dataset.pkl', 'rb') as f:\n    test_data = pkl.load(f)","metadata":{"execution":{"iopub.status.busy":"2023-03-10T13:10:49.024996Z","iopub.execute_input":"2023-03-10T13:10:49.026317Z","iopub.status.idle":"2023-03-10T13:10:49.302601Z","shell.execute_reply.started":"2023-03-10T13:10:49.026273Z","shell.execute_reply":"2023-03-10T13:10:49.301542Z"},"trusted":true},"execution_count":146,"outputs":[]},{"cell_type":"code","source":"test_dataset = TestDataset(test_data)\ntest_loader = DataLoader(dataset=test_dataset, batch_size=1, shuffle=False)","metadata":{"id":"f4_5O1t4xlYO","execution":{"iopub.status.busy":"2023-03-10T13:10:49.766192Z","iopub.execute_input":"2023-03-10T13:10:49.766586Z","iopub.status.idle":"2023-03-10T13:10:49.776032Z","shell.execute_reply.started":"2023-03-10T13:10:49.766551Z","shell.execute_reply":"2023-03-10T13:10:49.772345Z"},"trusted":true},"execution_count":147,"outputs":[]},{"cell_type":"markdown","source":"## Model","metadata":{}},{"cell_type":"code","source":"class JointNN(nn.Module):\n    def __init__(self, in_features):\n        super(JointNN, self).__init__()\n        self.text_seq = nn.Sequential(\n            nn.Linear(in_features, 576),\n            nn.BatchNorm1d(576),\n            nn.LeakyReLU(),\n            nn.Dropout(p=0.15),\n            nn.Linear(576, 384),\n            nn.BatchNorm1d(384),\n            nn.LeakyReLU(),\n            nn.Dropout(p=0.1),\n            nn.Linear(384, 576),\n            nn.LeakyReLU(),\n            nn.Linear(576, in_features),\n        )\n        self.audio_seq = nn.Sequential(\n            nn.Linear(in_features, 576),\n            nn.BatchNorm1d(576),\n            nn.LeakyReLU(),\n            nn.Dropout(p=0.15),\n            nn.Linear(576, 384),\n            nn.BatchNorm1d(384),\n            nn.LeakyReLU(),\n            nn.Dropout(p=0.1),\n            nn.Linear(384, 576),\n            nn.LeakyReLU(),\n            nn.Linear(576, in_features),\n        )\n\n    def forward(self, x_text, x_audio):\n        x1 = self.text_seq(x_text)\n        x2 = self.audio_seq(x_audio)\n        return x1, x2","metadata":{"execution":{"iopub.status.busy":"2023-03-10T13:09:31.595811Z","iopub.execute_input":"2023-03-10T13:09:31.596198Z","iopub.status.idle":"2023-03-10T13:09:31.606279Z","shell.execute_reply.started":"2023-03-10T13:09:31.596163Z","shell.execute_reply":"2023-03-10T13:09:31.605123Z"},"trusted":true},"execution_count":131,"outputs":[]},{"cell_type":"code","source":"class SimilarityModel:\n    def __init__(self, path_to_multimodal_model, sampling_rate=16000, threshold=0.5):\n      self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n      self.audio_processor = AutoProcessor.from_pretrained(\"facebook/wav2vec2-base-960h\")\n      self.audio_model = Wav2Vec2Model.from_pretrained(\"facebook/wav2vec2-base-960h\").to(self.device)\n      self.tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n      self.text_model = AutoModel.from_pretrained(\"bert-base-uncased\").to(self.device)\n      self.threshold = threshold\n      self.nn_model = torch.load(path_to_multimodal_model)\n      self.nn_model.eval()\n      self.nn_model = self.nn_model.to(self.device)\n      self.sampling_rate = sampling_rate\n\n    def cosine_similarity(self, embedding1, embedding2):\n      dim = 1\n      embedding1 = F.normalize(embedding1, p=2, dim=dim)\n      embedding2 = F.normalize(embedding2, p=2, dim=dim)\n\n      dot_product = torch.sum(embedding1 * embedding2, dim=dim)\n\n      magnitude1 = torch.norm(embedding1, p=2, dim=dim)\n      magnitude2 = torch.norm(embedding2, p=2, dim=dim)\n\n      cosine_sim = dot_product / (magnitude1 * magnitude2)\n\n      return cosine_sim\n\n    def predict(self, audios, texts, threshold=None, is_query=False):\n      audio_embs = []\n      for audio in audios:\n        inputs = self.audio_processor(audio, sampling_rate=self.sampling_rate, return_tensors=\"pt\", padding=True).to(device)\n        outputs = self.audio_model(**inputs)\n        last_hidden_states = outputs.last_hidden_state.squeeze(0)\n        audio_embedding = last_hidden_states.mean(dim=0)\n        audio_embs.append(audio_embedding)\n      \n\n      text_embs = []\n      for text in texts:\n        inputs = self.tokenizer(text, return_tensors=\"pt\").to(device)\n        outputs = self.text_model(**inputs)\n        embedding = outputs.last_hidden_state.squeeze(0)\n        text_embedding = embedding.mean(dim=0)\n        text_embs.append(text_embedding)\n      if is_query:\n        item = text_embs[0]\n        for i in range(len(audios) - 1):\n          text_embs.append(item.clone())\n\n\n      audio_embedding = torch.stack(audio_embs)\n      text_embedding = torch.stack(text_embs)\n      text_embedding = text_embedding.to(self.device)\n      audio_embedding = audio_embedding.to(self.device)\n\n      text_final_emb, audio_final_emb = self.nn_model(text_embedding, audio_embedding)\n      cosine_similarity = self.cosine_similarity(text_final_emb, audio_final_emb)\n\n      final_threshold = threshold if threshold else self.threshold\n\n      return cosine_similarity, (cosine_similarity >= final_threshold).int()\n\n    def retrieve_relevant_audios(self, audios, query, threshold=None):\n      return self.predict(audios, [query], is_query=True, threshold=threshold)","metadata":{"id":"L7zKAiQin8wX","execution":{"iopub.status.busy":"2023-03-10T13:33:13.818423Z","iopub.execute_input":"2023-03-10T13:33:13.819317Z","iopub.status.idle":"2023-03-10T13:33:13.836809Z","shell.execute_reply.started":"2023-03-10T13:33:13.819270Z","shell.execute_reply":"2023-03-10T13:33:13.835511Z"},"trusted":true},"execution_count":189,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\ndevice","metadata":{"execution":{"iopub.status.busy":"2023-03-10T13:33:13.874871Z","iopub.execute_input":"2023-03-10T13:33:13.876071Z","iopub.status.idle":"2023-03-10T13:33:13.884876Z","shell.execute_reply.started":"2023-03-10T13:33:13.876023Z","shell.execute_reply":"2023-03-10T13:33:13.883615Z"},"trusted":true},"execution_count":190,"outputs":[{"execution_count":190,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}]},{"cell_type":"code","source":"PATH = 'final_model.pt'\nmodel = torch.load(PATH)","metadata":{"execution":{"iopub.status.busy":"2023-03-10T13:40:01.787474Z","iopub.execute_input":"2023-03-10T13:40:01.788564Z","iopub.status.idle":"2023-03-10T13:40:02.351447Z","shell.execute_reply.started":"2023-03-10T13:40:01.788517Z","shell.execute_reply":"2023-03-10T13:40:02.350215Z"},"trusted":true},"execution_count":213,"outputs":[]},{"cell_type":"markdown","source":"### CLAP","metadata":{}},{"cell_type":"markdown","source":"## Test and Evaluation","metadata":{}},{"cell_type":"code","source":"def evaluate(model, dataloader):\n    total_hits_1 = 0\n    total_mrr = 0\n    total_instances = 0\n    total_labels = []\n    total_predictions = []\n\n    with torch.no_grad():\n        for text, candidates, label in tqdm(dataloader):\n            batch_size = label.size(0)\n            text = text[0]\n            candidates = candidates.to(device)\n            candidates = candidates.squeeze()\n            label = label.to(device)\n\n            # Compute text-to-candidates similarities\n            text_candidate_cosine_similarities, res = model.retrieve_relevant_audios(candidates, text, threshold=0.6)\n\n            # Compute Hits@1\n            _, predicted_idx = torch.max(text_candidate_cosine_similarities, dim=0)\n            hits_1 = torch.sum(predicted_idx == label)\n            total_hits_1 += hits_1.item()\n\n            # Compute MRR\n            candidate_ranks = torch.argsort(text_candidate_cosine_similarities, descending=True)\n            candidate_ranks = candidate_ranks.tolist()\n            label_rank = candidate_ranks.index(label.item())\n            reciprocal_rank = 1 / (label_rank + 1)\n            total_mrr += reciprocal_rank\n\n            # Record predictions and labels\n            predictions = res[label[0]].cpu()\n            total_labels.append(1)\n            total_predictions.append(predictions)\n\n            total_instances += batch_size\n\n    # Compute average metrics over all instances\n    avg_hits_1 = total_hits_1 / total_instances\n    avg_mrr = total_mrr / total_instances\n    precision = precision_score(total_labels, total_predictions, average='macro')\n    recall = recall_score(total_labels, total_predictions, average='macro')\n    f1 = f1_score(total_labels, total_predictions, average='macro')\n    accuracy = accuracy_score(total_labels, total_predictions)\n\n    return {\n        'Hits@1': avg_hits_1,\n        'MRR': avg_mrr,\n        'Precision': precision,\n        'Recall': recall,\n        'F1': f1,\n        'Accuracy': accuracy\n    }","metadata":{"id":"IZrEStF2195S","outputId":"2fbdc299-3adf-4cd7-adad-e82df3fcf07a","execution":{"iopub.status.busy":"2023-03-10T13:41:08.211329Z","iopub.execute_input":"2023-03-10T13:41:08.212304Z","iopub.status.idle":"2023-03-10T13:41:08.224856Z","shell.execute_reply.started":"2023-03-10T13:41:08.212264Z","shell.execute_reply":"2023-03-10T13:41:08.223726Z"},"trusted":true},"execution_count":220,"outputs":[]},{"cell_type":"code","source":"results = evaluate(model, test_loader)\ntable = []\nfor i in range(len(results)):\n    table.append([list(results.keys())[i], list(results.values())[i]])\nprint(tabulate(table, ['Metrics', 'Values'], tablefmt=\"grid\"))","metadata":{"execution":{"iopub.status.busy":"2023-03-10T13:41:08.227402Z","iopub.execute_input":"2023-03-10T13:41:08.228134Z","iopub.status.idle":"2023-03-10T13:41:36.756817Z","shell.execute_reply.started":"2023-03-10T13:41:08.228067Z","shell.execute_reply":"2023-03-10T13:41:36.755753Z"},"trusted":true},"execution_count":221,"outputs":[{"name":"stderr","text":"  0%|          | 0/300 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n100%|██████████| 300/300 [00:28<00:00, 10.53it/s]","output_type":"stream"},{"name":"stdout","text":"+-----------+-----------+\n| Metrics   |    Values |\n+===========+===========+\n| Hits@1    | 0.163333  |\n+-----------+-----------+\n| MRR       | 0.406278  |\n+-----------+-----------+\n| Precision | 0.5       |\n+-----------+-----------+\n| Recall    | 0.05      |\n+-----------+-----------+\n| F1        | 0.0909091 |\n+-----------+-----------+\n| Accuracy  | 0.1       |\n+-----------+-----------+\n","output_type":"stream"},{"name":"stderr","text":"\n/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Finding best hyper parameteres","metadata":{}},{"cell_type":"code","source":"# find best hyperparameter\n\nsize = len(audios)\nlabels = []\ntext_series = []\naudio_series = []\n\nfor i in range(size):\n  for j in range(size):\n    text_series.append(texts[i])\n    audio_series.append(audios[j])\n    labels.append(1 if i == j else 0)              ","metadata":{"id":"YQQCowKY2BWd","execution":{"iopub.status.busy":"2023-03-09T23:11:53.697537Z","iopub.execute_input":"2023-03-09T23:11:53.698278Z","iopub.status.idle":"2023-03-09T23:11:53.704998Z","shell.execute_reply.started":"2023-03-09T23:11:53.698234Z","shell.execute_reply":"2023-03-09T23:11:53.703668Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def accuracy_of_model(model, audios, texts, labels, threshold):\n  result = model.predict(audios, texts, threshold=threshold)\n  accuracy = accuracy_score(result.detach().cpu(), labels)\n  return accuracy","metadata":{"id":"C8qi7KIbJBUv","execution":{"iopub.status.busy":"2023-03-09T23:11:57.060679Z","iopub.execute_input":"2023-03-09T23:11:57.062313Z","iopub.status.idle":"2023-03-09T23:11:57.071315Z","shell.execute_reply.started":"2023-03-09T23:11:57.062259Z","shell.execute_reply":"2023-03-09T23:11:57.069767Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"    torch.cuda.empty_cache()\n    torch.cuda.ipc_collect()\n    gc.collect()","metadata":{"execution":{"iopub.status.busy":"2023-03-09T23:11:58.253471Z","iopub.execute_input":"2023-03-09T23:11:58.254158Z","iopub.status.idle":"2023-03-09T23:11:58.886818Z","shell.execute_reply.started":"2023-03-09T23:11:58.254122Z","shell.execute_reply":"2023-03-09T23:11:58.885640Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"zipped_lists = list(zip(audio_series, text_series, labels))\n\nn = 10\nsampled_tuples = random.sample(zipped_lists, n)\n\n# unzip the sampled tuples into separate lists\naudios_test, texts_test, labels_test = zip(*sampled_tuples)","metadata":{"execution":{"iopub.status.busy":"2023-03-09T23:11:59.032039Z","iopub.execute_input":"2023-03-09T23:11:59.032452Z","iopub.status.idle":"2023-03-09T23:11:59.044773Z","shell.execute_reply.started":"2023-03-09T23:11:59.032413Z","shell.execute_reply":"2023-03-09T23:11:59.042828Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"threshold_list = [0.05 * i for i in range(4,18)]\nbest_accuracy = 0\nbest_threshold = 0\nfor threshold in threshold_list:\n    torch.cuda.empty_cache()\n    torch.cuda.ipc_collect()\n    accuracy = accuracy_of_model(final_model, audios_test, texts_test, labels_test, threshold)\n    print(f\"Accuracy with threshold {threshold:.2f} = {accuracy * 100:.2f}%\")\n    if accuracy > best_accuracy:\n        best_threshold = threshold\n        best_accuracy = accuracy\n    gc.collect()\n\nprint(f\"Best threshold is {best_threshold:.2f}\")\nprint(f\"Best accuracy is {best_accuracy:.2f}\")","metadata":{"id":"fnlcYiHzKpdV","outputId":"be6d07f9-76c0-4f29-bba4-9eabf52a5617","execution":{"iopub.status.busy":"2023-03-09T23:12:00.407226Z","iopub.execute_input":"2023-03-09T23:12:00.407818Z","iopub.status.idle":"2023-03-09T23:12:21.560163Z","shell.execute_reply.started":"2023-03-09T23:12:00.407779Z","shell.execute_reply":"2023-03-09T23:12:21.557048Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"PATH = \"multimodal_model.pt\"\nbest_model = SimilarityModel(PATH, threshold=best_threshold)","metadata":{"id":"4NNldYqkMsvO","outputId":"4f7ad90e-4856-4d26-e53e-a9532a46f98d","execution":{"iopub.status.busy":"2023-03-09T23:15:41.185917Z","iopub.execute_input":"2023-03-09T23:15:41.186961Z","iopub.status.idle":"2023-03-09T23:15:44.999098Z","shell.execute_reply.started":"2023-03-09T23:15:41.186919Z","shell.execute_reply":"2023-03-09T23:15:44.998032Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"PATH = \"final_relevant_model_v2.pt\"\n\n# Save\ntorch.save(best_model, PATH)","metadata":{"id":"zCDY17vCM_Ls","execution":{"iopub.status.busy":"2023-03-09T23:15:46.194244Z","iopub.execute_input":"2023-03-09T23:15:46.194639Z","iopub.status.idle":"2023-03-09T23:15:48.094738Z","shell.execute_reply.started":"2023-03-09T23:15:46.194579Z","shell.execute_reply":"2023-03-09T23:15:48.092719Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load\nPATH = \"final_relevant_model.pt\"\nbest_model = torch.load(PATH)\nbest_model.eval()\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nbest_model = best_model.to(device)","metadata":{"id":"sHu7ZzOyFU2S"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from IPython.display import FileLink\nFileLink(r'final_relevant_model_v2.pt')","metadata":{"execution":{"iopub.status.busy":"2023-03-09T23:21:54.611205Z","iopub.execute_input":"2023-03-09T23:21:54.611661Z","iopub.status.idle":"2023-03-09T23:21:54.620833Z","shell.execute_reply.started":"2023-03-09T23:21:54.611617Z","shell.execute_reply":"2023-03-09T23:21:54.619519Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from IPython.display import FileLink\nFileLink(r'multimodal_model.pt')","metadata":{"execution":{"iopub.status.busy":"2023-03-09T23:30:02.780200Z","iopub.execute_input":"2023-03-09T23:30:02.781070Z","iopub.status.idle":"2023-03-09T23:30:02.788844Z","shell.execute_reply.started":"2023-03-09T23:30:02.781031Z","shell.execute_reply":"2023-03-09T23:30:02.787723Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}